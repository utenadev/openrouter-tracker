# openrouter-tracker å®Ÿè£…ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ (v2)

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

OpenRouterã®ç„¡æ–™ãƒ¢ãƒ‡ãƒ«ã®é€±é–“ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¿½è·¡ã—ã€æ¯æ—¥2å›ï¼ˆ6:00 AM, 6:00 PMï¼‰ã«Discordã¸é€šçŸ¥ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã€‚

---

## ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

```
~/openrouter-tracker/
â”œâ”€â”€ fetch_openrouter.py      # ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ discord_notifier.py      # Discordé€šçŸ¥
â”œâ”€â”€ db.py                    # SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ
â”œâ”€â”€ config.yaml              # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ models.db                # SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆå®Ÿè¡Œæ™‚ã«ä½œæˆï¼‰
â”œâ”€â”€ logs/                    # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
â”‚   â””â”€â”€ app.log
â”œâ”€â”€ setup.sh                 # åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â””â”€â”€ requirements.txt         # Pythonä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
```

---

## å„ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Ÿè£…

### 1. requirements.txt

```
pyyaml>=6.0
requests>=2.31.0
```

---

### 2. config.yaml

```yaml
# Discordè¨­å®š
discord:
  webhook_url: "YOUR_DISCORD_WEBHOOK_URL_HERE"
  enabled: true

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
database:
  path: "models.db"

# APIè¨­å®š
api:
  base_url: "https://openrouter.ai/models?max_price=0&order=top-weekly&limit=50"
  timeout: 30
  max_retries: 2
  retry_delay: 5
  user_agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"

# ãƒ­ã‚°è¨­å®š
logging:
  file: "logs/app.log"
  level: "INFO"
  max_size_mb: 10
  backup_count: 5

# å°†æ¥çš„ãªLLMä¿®æ­£æ©Ÿèƒ½ï¼ˆæ¬¡ã®ãƒ•ã‚§ãƒ¼ã‚ºç”¨ï¼‰
llm_parser:
  enabled: false
  provider: "openrouter"
  model: "anthropic/claude-3.5-sonnet"
  api_key: "YOUR_API_KEY_HERE"
  fallback_to_manual: true
```

---

### 3. db.py

```python
import sqlite3
from datetime import datetime
from typing import List, Dict, Optional, Set
from dataclasses import dataclass

@dataclass
class Model:
    id: str
    name: str
    provider: str
    context_length: int
    description: str
    created_at: str
    updated_at: str

@dataclass
class DailyStats:
    model_id: str
    date: str
    rank: int
    weekly_tokens: float
    prompt_price: float
    completion_price: float

class Database:
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.conn = None

    def __enter__(self):
        self.conn = sqlite3.connect(self.db_path, timeout=30.0)
        self.conn.execute("PRAGMA journal_mode=WAL")
        self.conn.row_factory = sqlite3.Row
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.conn:
            self.conn.close()

    def init_db(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–"""
        with self.conn:
            self.conn.execute("""
                CREATE TABLE IF NOT EXISTS models (
                    id TEXT PRIMARY KEY,
                    name TEXT NOT NULL,
                    provider TEXT NOT NULL,
                    context_length INTEGER,
                    description TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)

            self.conn.execute("""
                CREATE TABLE IF NOT EXISTS daily_stats (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    model_id TEXT NOT NULL,
                    date DATE NOT NULL,
                    rank INTEGER NOT NULL,
                    weekly_tokens REAL NOT NULL,
                    prompt_price REAL,
                    completion_price REAL,
                    FOREIGN KEY (model_id) REFERENCES models(id),
                    UNIQUE(model_id, date)
                )
            """)

            self.conn.execute("""
                CREATE TABLE IF NOT EXISTS history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    model_id TEXT,
                    event TEXT NOT NULL,
                    details TEXT,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)

            self.conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_daily_stats_date
                ON daily_stats(date)
            """)

            self.conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_daily_stats_rank
                ON daily_stats(rank, date)
            """)

    def upsert_model(self, model: Model):
        """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®æ›´æ–°ã¾ãŸã¯æ–°è¦è¿½åŠ """
        with self.conn:
            cursor = self.conn.execute("""
                INSERT INTO models (id, name, provider, context_length, description)
                VALUES (?, ?, ?, ?, ?)
                ON CONFLICT(id) DO UPDATE SET
                    name = excluded.name,
                    provider = excluded.provider,
                    context_length = excluded.context_length,
                    description = excluded.description,
                    updated_at = CURRENT_TIMESTAMP
            """, (model.id, model.name, model.provider, model.context_length, model.description))

            # æ–°è¦è¿½åŠ ã®å ´åˆã€å±¥æ­´ã«è¨˜éŒ²
            if cursor.rowcount > 0 and cursor.lastrowid > 0:
                is_new = self.conn.execute(
                    "SELECT COUNT(*) FROM history WHERE model_id = ? AND event = 'new'",
                    (model.id,)
                ).fetchone()[0] == 0

                if is_new:
                    self.conn.execute("""
                        INSERT INTO history (model_id, event, details)
                        VALUES (?, 'new', ?)
                    """, (model.id, f"New model added: {model.name}"))

    def save_daily_stats(self, stats: List[DailyStats]):
        """æ—¥æ¬¡çµ±è¨ˆã‚’ä¿å­˜"""
        today = datetime.now().strftime('%Y-%m-%d')

        with self.conn:
            for stat in stats:
                self.conn.execute("""
                    INSERT OR REPLACE INTO daily_stats
                    (model_id, date, rank, weekly_tokens, prompt_price, completion_price)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (stat.model_id, stat.date, stat.rank, stat.weekly_tokens,
                      stat.prompt_price, stat.completion_price))

    def get_latest_rankings_before(self, date_threshold: str) -> Dict[str, int]:
        """æŒ‡å®šæ—¥ä»¥å‰ã®ç›´è¿‘ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å–å¾—ï¼ˆ24æ™‚é–“ä»¥ä¸Šå‰ã®æ¯”è¼ƒç”¨ï¼‰"""
        # æŒ‡å®šæ—¥ä»¥å‰ã§æœ€ã‚‚æ–°ã—ã„æ—¥ä»˜ã‚’å–å¾—
        latest_date_row = self.conn.execute("""
            SELECT MAX(date) as max_date
            FROM daily_stats
            WHERE date <= ?
        """, (date_threshold,)).fetchone()

        if not latest_date_row or not latest_date_row['max_date']:
            return {}

        target_date = latest_date_row['max_date']
        
        previous_rankings = self.conn.execute("""
            SELECT model_id, rank
            FROM daily_stats
            WHERE date = ?
        """, (target_date,)).fetchall()

        return {row['model_id']: row['rank'] for row in previous_rankings}

    def get_top_models_by_tokens(self, date: str, limit: int = 5) -> List[Dict]:
        """æŒ‡å®šæ—¥ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãƒˆãƒƒãƒ—Nãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
        return self.conn.execute("""
            SELECT m.*, d.rank, d.weekly_tokens
            FROM daily_stats d
            JOIN models m ON d.model_id = m.id
            WHERE d.date = ?
            ORDER BY d.rank
            LIMIT ?
        """, (date, limit)).fetchall()

    def get_all_models(self) -> List[Model]:
        """å…¨ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
        rows = self.conn.execute("SELECT * FROM models").fetchall()
        return [Model(**dict(row)) for row in rows]
    
    def get_all_model_ids(self) -> Set[str]:
        """å…¨ãƒ¢ãƒ‡ãƒ«IDã®ã‚»ãƒƒãƒˆã‚’å–å¾—"""
        rows = self.conn.execute("SELECT id FROM models").fetchall()
        return {row['id'] for row in rows}

    def detect_new_models(self, current_models: List[str]) -> List[str]:
        """æ–°è¦ãƒ¢ãƒ‡ãƒ«ã‚’æ¤œå‡º"""
        existing_models = self.get_all_model_ids()
        new_models = [model_id for model_id in current_models if model_id not in existing_models]
        return new_models
```

---

### 4. discord_notifier.py

```python
import requests
import logging
from typing import Dict, List
from datetime import datetime

logger = logging.getLogger(__name__)

class DiscordNotifier:
    def __init__(self, webhook_url: str, enabled: bool = True):
        self.webhook_url = webhook_url
        self.enabled = enabled

    def send_top5_notification(self, models: List[Dict], previous_rankings: Dict[str, int]):
        """ãƒˆãƒƒãƒ—5ãƒ¢ãƒ‡ãƒ«ã®é€šçŸ¥ã‚’é€ä¿¡"""
        if not self.enabled:
            logger.info("Discord notifications are disabled")
            return

        today = datetime.now().strftime('%Y-%m-%d')

        embed = {
            "title": f"ğŸ“Š OpenRouter ç„¡æ–™ãƒ¢ãƒ‡ãƒ« é€±é–“ãƒ©ãƒ³ã‚­ãƒ³ã‚° Top 5",
            "description": f"ğŸ“… {today}",
            "color": 0x5865F2,
            "fields": []
        }

        for i, model in enumerate(models[:5], 1):
            prev_rank = previous_rankings.get(model['id'], i) # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ç¾åœ¨ã®é †ä½ã¨ä»®å®š
            change = prev_rank - i

            if change > 0:
                change_emoji = "ğŸ“ˆ"
                change_text = f"#{prev_rank} â†’ #{i} (+{change})"
            elif change < 0:
                change_emoji = "ğŸ“‰"
                change_text = f"#{prev_rank} â†’ #{i} ({change})"
            else:
                change_emoji = "â¡ï¸"
                change_text = f"#{i}"

            # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            weekly_tokens = model['weekly_tokens']
            if weekly_tokens >= 1000:
                tokens_str = f"{weekly_tokens/1000:.2f}B"
            else:
                tokens_str = f"{weekly_tokens:.1f}M"

            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            context = model['context_length']
            if context >= 1024:
                context_str = f"{context//1024}K"
            else:
                context_str = str(context)

            field = {
                "name": f"{i}. {model['name']}",
                "value": f"ğŸ”¸ é€±é–“ãƒˆãƒ¼ã‚¯ãƒ³: {tokens_str}\n" +
                        f"ğŸ“ˆ å‰æ—¥é †ä½: {change_text} {change_emoji}\n" +
                        f"ğŸ“ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context_str}",
                "inline": False
            }
            embed["fields"].append(field)

        self.send_embed(embed)

    def send_new_models_notification(self, new_models: List[Dict]):
        """æ–°è¦è¿½åŠ ãƒ¢ãƒ‡ãƒ«ã®é€šçŸ¥"""
        if not self.enabled or not new_models:
            return

        embed = {
            "title": "ğŸ†• æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸ",
            "color": 0x00FF00,
            "fields": []
        }

        for model in new_models:
            field = {
                "name": model['name'],
                "value": f"ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {model['provider']}\n" +
                        f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {model['context_length']:,}",
                "inline": False
            }
            embed["fields"].append(field)

        self.send_embed(embed)

    def send_summary(self, total_models: int, total_tokens: float, new_models_count: int):
        """çµ±è¨ˆã‚µãƒãƒªãƒ¼ã®é€šçŸ¥"""
        if not self.enabled:
            return

        if total_tokens >= 1000:
            tokens_str = f"{total_tokens/1000:.2f}B"
        else:
            tokens_str = f"{total_tokens:.1f}M"

        embed = {
            "title": "ğŸ“Š çµ±è¨ˆã‚µãƒãƒªãƒ¼",
            "color": 0x1E88E5,
            "fields": [
                {"name": "ç·ãƒ¢ãƒ‡ãƒ«æ•°", "value": str(total_models), "inline": True},
                {"name": "ä»Šé€±ã®ç·ãƒˆãƒ¼ã‚¯ãƒ³", "value": tokens_str, "inline": True},
                {"name": "è¿½åŠ ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«", "value": str(new_models_count), "inline": True}
            ]
        }

        self.send_embed(embed)

    def send_embed(self, embed: Dict):
        """åŸ‹ã‚è¾¼ã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡"""
        payload = {"embeds": [embed]}

        try:
            time.sleep(1)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            response = requests.post(self.webhook_url, json=payload, timeout=10)
            response.raise_for_status()
            logger.info("Discord notification sent successfully")
        except Exception as e:
            logger.error(f"Failed to send Discord notification: {e}")
            # ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ 
            time.sleep(2)
            try:
                response = requests.post(self.webhook_url, json=payload, timeout=10)
                response.raise_for_status()
                logger.info("Discord notification sent successfully on retry")
            except Exception as e:
                logger.error(f"Failed to send Discord notification on retry: {e}")
```

---

### 5. fetch_openrouter.py

```python
#!/usr/bin/env python3
import re
import time
import yaml
import logging
import requests
from logging.handlers import RotatingFileHandler
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict
from db import Database, Model, DailyStats
from discord_notifier import DiscordNotifier

# å®šæ•°å®šç¾©
BASE_DIR = Path(__file__).parent.resolve()

# ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©
MODEL_PATTERN = r'\*   \[(.*?)](https://openrouter\.ai/[^)]+)\)\s+(\d+\.?\d*[MB]?) tokens'
CONTEXT_PATTERN = r'(\d+K?) context'
PRICE_INPUT_PATTERN = r'\$(\d+\.?\d*)/M input tokens'
PRICE_OUTPUT_PATTERN = r'\$(\d+\.?\d*)/M output tokens'
PROVIDER_PATTERN = r'by \[(.*?)\]'

def setup_logging(config: Dict):
    """ãƒ­ã‚°è¨­å®š"""
    log_file = Path(config['logging']['file'])
    
    # çµ¶å¯¾ãƒ‘ã‚¹ã«è§£æ±º
    if not log_file.is_absolute():
        BASE_DIR = Path(__file__).parent.resolve()
        log_file = BASE_DIR / log_file
        
    log_file.parent.mkdir(parents=True, exist_ok=True)

    logger = logging.getLogger()
    logger.setLevel(getattr(logging, config['logging']['level']))

    # æ—¢å­˜ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¯ãƒªã‚¢
    logger.handlers.clear()

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãï¼‰
    file_handler = RotatingFileHandler(
        log_file,
        maxBytes=config['logging']['max_size_mb'] * 1024 * 1024,
        backupCount=config['logging']['backup_count']
    )
    file_handler.setFormatter(logging.Formatter(
        '%(asctime)s | %(levelname)-8s | %(name)s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    ))
    logger.addHandler(file_handler)

    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(logging.Formatter(
        '%(asctime)s | %(levelname)-8s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    ))
    console_handler.setLevel(logging.WARNING)
    logger.addHandler(console_handler)

    return logger

def load_config(config_path: str = "config.yaml") -> Dict:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
    # çµ¶å¯¾ãƒ‘ã‚¹ã§configãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    abs_config_path = BASE_DIR / config_path
    
    with open(abs_config_path, 'r') as f:
        config = yaml.safe_load(f)

    # ç›¸å¯¾ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›ï¼ˆconfigã«æ›¸ã‹ã‚ŒãŸãƒ‘ã‚¹ãŒç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã®ã¿ï¼‰
    db_path = Path(config['database']['path'])
    if not db_path.is_absolute():
        config['database']['path'] = str(BASE_DIR / db_path)
        
    log_path = Path(config['logging']['file'])
    if not log_path.is_absolute():
        config['logging']['file'] = str(BASE_DIR / log_path)

    return config

def normalize_tokens(tokens_str: str) -> float:
    """ãƒˆãƒ¼ã‚¯ãƒ³æ–‡å­—åˆ—ã‚’æ­£è¦åŒ–ï¼ˆM/Bã‚’æ•°å€¤ã«å¤‰æ›ï¼‰"""
    tokens_str = tokens_str.strip().upper()
    tokens_str = tokens_str.replace(',', '')
    tokens_str = tokens_str.replace('TOKENS', '')

    if tokens_str.endswith('B'):
        return float(tokens_str[:-1]) * 1000
    elif tokens_str.endswith('M'):
        return float(tokens_str[:-1])
    else:
        return float(tokens_str)

def normalize_context(context_str: str) -> int:
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·æ–‡å­—åˆ—ã‚’æ­£è¦åŒ–ï¼ˆKã‚’æ•°å€¤ã«å¤‰æ›ï¼‰"""
    context_str = context_str.strip()
    if context_str.endswith('K'):
        return int(context_str[:-1]) * 1024
    else:
        return int(context_str)

def fetch_markdown(config: Dict, logger: logging.Logger) -> str:
    """OpenRouter APIã‹ã‚‰Markdownãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    max_retries = config['api']['max_retries']
    retry_delay = config['api']['retry_delay']
    last_error = None

    # ãƒ˜ãƒƒãƒ€ãƒ¼ã®è¨­å®šï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å«ã‚€ï¼‰
    headers = {
        'User-Agent': config['api']['user_agent']
    }

    for attempt in range(max_retries + 1):
        try:
            response = requests.get(
                config['api']['base_url'],
                timeout=config['api']['timeout'],
                headers=headers
            )
            response.raise_for_status()

            if not response.text.strip():
                raise ValueError("Empty response from API")

            return response.text

        except Exception as e:
            last_error = e
            if attempt < max_retries:
                sleep_time = retry_delay * (attempt + 1)
                logger.warning(f"Attempt {attempt + 1} failed: {e}. Retrying in {sleep_time}s...")
                time.sleep(sleep_time)
            else:
                logger.error(f"Failed to fetch data after {max_retries + 1} attempts")
                raise RuntimeError(f"Failed after {max_retries + 1} attempts: {last_error}")

def parse_markdown(markdown: str, logger: logging.Logger) -> List[Dict]:
    """Markdownã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’æŠ½å‡º"""
    models = []

    # è¡Œã”ã¨ã«å‡¦ç†
    lines = markdown.split('\n')
    
    for line in lines:
        # ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ³ãƒˆãƒªã‚’æŠ½å‡ºï¼ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒå«ã¾ã‚Œã‚‹è¡Œã®ã¿ï¼‰
        match = re.search(MODEL_PATTERN, line)
        if not match:
            continue
        
        name, tokens = match.groups()
        
        # URLã‚’æŠ½å‡º
        url_match = re.search(r'\((https://openrouter\.ai/[^)]+)\)', line)
        if not url_match:
            continue
        
        url = url_match.group(1)
        model_id = url.split('openrouter.ai/')[-1]
        
        # ãƒ¢ãƒ‡ãƒ«åã‹ã‚‰ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åã‚’æŠ½å‡ºï¼ˆä¾‹: "Xiaomi: MiMo-V2-Flash (free)" â†’ "Xiaomi"ï¼‰
        if ':' in name:
            provider = name.split(':')[0].strip()
            # ãƒ¢ãƒ‡ãƒ«åã‹ã‚‰ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åã‚’é™¤å»
            clean_name = name.split(':')[1].strip()
        else:
            provider = "Unknown"
            clean_name = name
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’æŠ½å‡º
        context_match = re.search(CONTEXT_PATTERN, line)
        context_length = normalize_context(context_match.group(1)) if context_match else 0

        # ä¾¡æ ¼ã‚’æŠ½å‡º
        input_price_match = re.search(PRICE_INPUT_PATTERN, line)
        input_price = float(input_price_match.group(1)) if input_price_match else 0.0

        output_price_match = re.search(PRICE_OUTPUT_PATTERN, line)
        output_price = float(output_price_match.group(1)) if output_price_match else 0.0

        models.append({
            'id': model_id,
            'name': clean_name,
            'provider': provider,
            'context_length': context_length,
            'description': '',
            'weekly_tokens': normalize_tokens(tokens),
            'prompt_price': input_price,
            'completion_price': output_price
        })

    if not models:
        logger.error("No models found in markdown data")
        raise ValueError("Failed to parse models from markdown")

    logger.info(f"Parsed {len(models)} models")
    return models

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # è¨­å®šèª­ã¿è¾¼ã¿
    config = load_config()

    # ãƒ­ã‚°è¨­å®š
    logger = setup_logging(config)
    logger.info("=" * 50)
    logger.info("Starting openrouter-tracker")

    try:
        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        logger.info("Fetching markdown data...")
        markdown = fetch_markdown(config, logger)

        # ãƒ‘ãƒ¼ã‚¹
        logger.info("Parsing markdown data...")
        models_data = parse_markdown(markdown, logger)

        # é€±é–“ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã§ã‚½ãƒ¼ãƒˆã—ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä½œæˆ
        models_data.sort(key=lambda x: x['weekly_tokens'], reverse=True)

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ
        db_path = Path(config['database']['path'])
        db_path.parent.mkdir(parents=True, exist_ok=True)
        
        new_models = []
        
        with Database(str(db_path)) as db:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
            db.init_db()

            # æ–°è¦ãƒ¢ãƒ‡ãƒ«æ¤œå‡ºï¼ˆUpsertå‰ã«ãƒã‚§ãƒƒã‚¯ï¼‰
            existing_ids = db.get_all_model_ids()
            current_ids = {m['id'] for m in models_data}
            new_model_ids = current_ids - existing_ids
            
            # æ–°è¦ãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ã‚’æŠ½å‡º
            new_models = [m for m in models_data if m['id'] in new_model_ids]
            
            if new_models:
                logger.info(f"Detected {len(new_models)} new models")

            # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ä¿å­˜
            for model_data in models_data:
                model = Model(
                    id=model_data['id'],
                    name=model_data['name'],
                    provider=model_data['provider'],
                    context_length=model_data['context_length'],
                    description='',
                    created_at=datetime.now().isoformat(),
                    updated_at=datetime.now().isoformat()
                )
                db.upsert_model(model)

            # æ—¥æ¬¡çµ±è¨ˆã‚’ä¿å­˜
            today = datetime.now().strftime('%Y-%m-%d')
            daily_stats = []
            for rank, model_data in enumerate(models_data, 1):
                stat = DailyStats(
                    model_id=model_data['id'],
                    date=today,
                    rank=rank,
                    weekly_tokens=model_data['weekly_tokens'],
                    prompt_price=model_data['prompt_price'],
                    completion_price=model_data['completion_price']
                )
                daily_stats.append(stat)

            db.save_daily_stats(daily_stats)
            logger.info(f"Saved {len(daily_stats)} daily stats")

        # Discordé€šçŸ¥
        notifier = DiscordNotifier(
            webhook_url=config['discord']['webhook_url'],
            enabled=config['discord']['enabled']
        )

        # å‰æ—¥ã®é †ä½ã‚’å–å¾— (24æ™‚é–“ä»¥ä¸Šå‰ã®ç›´è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã¨æ¯”è¼ƒ)
        # æœ¬æ—¥ãŒ 2026-01-02 ãªã‚‰ã€2026-01-01 ä»¥å‰ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        threshold_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        
        with Database(str(db_path)) as db:
            previous_rankings = db.get_latest_rankings_before(threshold_date)
            top_models = db.get_top_models_by_tokens(today, limit=5)

        # ãƒˆãƒƒãƒ—5é€šçŸ¥
        logger.info("Sending Discord notification...")
        notifier.send_top5_notification(top_models, previous_rankings)
        
        # æ–°è¦ãƒ¢ãƒ‡ãƒ«é€šçŸ¥
        if new_models:
            logger.info("Sending New Models notification...")
            notifier.send_new_models_notification(new_models)

        # ã‚µãƒãƒªãƒ¼é€šçŸ¥
        total_tokens = sum(m['weekly_tokens'] for m in models_data)
        
        notifier.send_summary(
            total_models=len(models_data),
            total_tokens=total_tokens,
            new_models_count=len(new_models)
        )
        
        # ã‚¨ãƒ©ãƒ¼é€šçŸ¥ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        # é€šçŸ¥ãŒæœ‰åŠ¹ãªå ´åˆã€ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã«ã‚‚é€šçŸ¥ã‚’é€ä¿¡ã™ã‚‹
        # try-exceptãƒ–ãƒ­ãƒƒã‚¯ã§ãƒ©ãƒƒãƒ—ã—ã¦ã€ã‚¨ãƒ©ãƒ¼æ™‚ã«ã‚‚é€šçŸ¥ã‚’é€ä¿¡ã™ã‚‹

        logger.info("Execution completed successfully")

    except Exception as e:
        logger.error(f"Error during execution: {e}", exc_info=True)
        # é€šçŸ¥ãŒæœ‰åŠ¹ãªã‚‰ã‚¨ãƒ©ãƒ¼é€šçŸ¥ã‚’é£›ã°ã—ã¦ã‚‚è‰¯ã„ãŒã€ã“ã“ã§ã¯ãƒ­ã‚°å‡ºåŠ›ã«ã¨ã©ã‚ã‚‹
        raise

if __name__ == "__main__":
    main()
```

---

### 6. setup.sh

```bash
#!/bin/bash
set -e

echo "Setting up openrouter-tracker..."

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p ~/openrouter-tracker/logs

# ä»®æƒ³ç’°å¢ƒã®ä½œæˆï¼ˆæ¨å¥¨ï¼‰
cd ~/openrouter-tracker
python3 -m venv venv

# .gitignoreã®ä½œæˆ
echo "venv/" > .gitignore
echo "__pycache__/" >> .gitignore
echo "*.db" >> .gitignore
echo "config.yaml" >> .gitignore
echo "logs/" >> .gitignore

# ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
./venv/bin/pip install --upgrade pip
./venv/bin/pip install -r requirements.txt

# config.yamlã®ä½œæˆï¼ˆã¾ã å­˜åœ¨ã—ãªã„å ´åˆï¼‰
if [ ! -f config.yaml ]; then
    echo "config.yaml not found. Please create it manually."
fi

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œæ¨©é™è¨­å®š
chmod +x fetch_openrouter.py

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
./venv/bin/python3 -c "from db import Database; db = Database('models.db'); db.__enter__(); db.init_db()"

echo "Setup complete!"
echo ""
echo "Next steps:"
echo "1. Edit config.yaml with your Discord webhook URL"
echo "2. Run: ./venv/bin/python3 fetch_openrouter.py"
echo "3. Add to crontab: crontab -e"
```

---

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

### 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®é…ç½®

```bash
# ãƒ›ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
mkdir -p ~/openrouter-tracker
cd ~/openrouter-tracker

# ä¸Šè¨˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦é…ç½®
```

### 2. ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
cd ~/openrouter-tracker
# ä»®æƒ³ç’°å¢ƒä½œæˆã¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
python3 -m venv venv
./venv/bin/pip install -r requirements.txt
```

### 3. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç·¨é›†

```bash
nano config.yaml
```

ä»¥ä¸‹ã®é …ç›®ã‚’ç·¨é›†ï¼š
- `discord.webhook_url`: å®Ÿéš›ã®Discord Webhook URLã«ç½®æ›
- `database.path`: `models.db` (ç›¸å¯¾ãƒ‘ã‚¹ã§OK)
- `logging.file`: `logs/app.log` (ç›¸å¯¾ãƒ‘ã‚¹ã§OK)

### 4. åˆæœŸå®Ÿè¡Œ

```bash
# ä»®æƒ³ç’°å¢ƒã®pythonã‚’ä½¿ç”¨
cd ~/openrouter-tracker
./venv/bin/python3 fetch_openrouter.py
```

### 5. Cronã®è¨­å®š

```bash
# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®crontabã‚’ç·¨é›†
crontab -e

# ä»¥ä¸‹ã‚’è¿½åŠ ï¼ˆãƒ•ãƒ«ãƒ‘ã‚¹ã§æŒ‡å®šï¼‰
0 6 * * * cd /home/USER/openrouter-tracker && /home/USER/openrouter-tracker/venv/bin/python3 fetch_openrouter.py
0 18 * * * cd /home/USER/openrouter-tracker && /home/USER/openrouter-tracker/venv/bin/python3 fetch_openrouter.py
```

â€» `USER` ã®éƒ¨åˆ†ã‚’å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã«ç½®æ›ã—ã¦ãã ã•ã„ã€‚

---

## å®Ÿè¡Œæ–¹æ³•

### æ‰‹å‹•å®Ÿè¡Œ

```bash
cd ~/openrouter-tracker
./venv/bin/python3 fetch_openrouter.py
```

### è‡ªå‹•å®Ÿè¡Œ

Cronã«ã‚ˆã‚Šã€æ¯æ—¥ 6:00 AM ã¨ 6:00 PM ã«è‡ªå‹•å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

---

## ãƒ­ã‚°ã®ç¢ºèª

```bash
tail -f ~/openrouter-tracker/logs/app.log
```

```